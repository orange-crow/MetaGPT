# A Review on the Memory of LLM Agent

## Awesome Papers

|   ID | Title                                                                                                                       | Author                                                      | Date       | Memory Model                                                                                                                                                                                                                                                                                                                                                                    | Code                                                                       |
|------|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------|
|    1 | [A-MEM: Agentic Memory for LLM Agents](https://arxiv.org/pdf/2502.12110)                                                    | Wujiang Xu(Rutgers University)                              | 2025-02-01 | 1. 基于 Zettelkasten 方法的动态知识网络构建 + 自动链接生成 + 记忆演化(复杂多跳推理能力的保证) + 上下文感知检索。<br> 2. A-MEM 在多个基础模型上均优于现有的最先进方法，特别是在需要复杂推理的多跳问答任务中表现尤为突出。<br>                                                                                                                                                    | https://github.com/WujiangXu/AgenticMemory                                 |
|    2 | [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://aclanthology.org/2024.acl-long.747.pdf)             | Adyasha Maharana(University of North Carolina, Chapel Hill) | 2024-08-01 | 1. 问答任务：LLMs在单跳和多跳问题上表现较好，但在时间推理和对抗性问题上表现较差。<br> 2. 事件总结任务：LLMs在总结对话中的事件时存在困难，尤其是在捕捉事件之间的因果和时间关系方面。<br> 3. 多模态对话生成任务：在多模态对话生成任务中，结合对话历史和相关观察（observations）的模型表现优于仅依赖对话历史的模型。这表明利用检索到的相关信息可以显著提高模型生成对话的质量。<br> | https://snap-research.github.io/locomo/, https://github.com/letta-ai/letta |
|    3 | [MemGPT: Towards LLMs as Operating Systems](https://arxiv.org/pdf/2310.08560)                                               | Charles(Berkeley)                                           | 2023-10-01 | 借鉴类似计算机分层内存管理机制, 实现能够分析远远超出基座 LLM 上下文窗口的大型文档: 分层存储架构（主上下文与外部上下文） + 函数调用驱动的动态上下文管理 + 事件驱动的控制流 + 基于优先级的上下文更新 + 多步检索与函数链式调用 + 长期记忆与动态更新。                                                                                                                              | https://github.com/letta-ai/letta, https://research.memgpt.ai/             |
|    4 | [Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations](https://arxiv.org/pdf/2308.16505) | Xu Huang(Microsoft)                                         | 2023-08-01 | 论文以 LLMs 作为大脑，以推荐模型作为工具，来应对LLM在**对话推荐系统**中的领域知识缺失问题。<br> 1. 将query、工具（召回、排序）以及用户的反馈信息和LLM进行交互，而不是传入候选 items的名称。而将候选 item 放入（工具的）共享候选缓冲区。<br> 2. 结合长期与短期记忆，以保持对用户偏好的全面理解。<br>                                                                             | https://github.com/microsoft/RecAI                                         |
|    5 | [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442)                              | Joon(Stanford University)                                   | 2023-04-01 | 带时间戳的事件记忆流 + 多因子相关性检索（近期性/重要性/相似性）+ 定期反思生成抽象洞察 + 动态计划与环境响应 + 记忆驱动的个性化对话生成；                                                                                                                                                                                                                                         | https://github.com/joonspk-research/generative_agents                      |

## Others


1. [The Era of Experience](https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf): agent结构的转变，传统的“状态-动作-奖励” -> “经验流 + 自我目标感知 + 长期策略演化”; 2025-04-10

2. [The Second Half](https://ysymyth.github.io/The-Second-Half): 先验知识(prior)比环境(environment)以及经验更重要。 2025-04

3. [Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents](https://arxiv.org/pdf/2502.06975): 无实验论证； 2025-02

4. [ZEP: A TEMPORAL KNOWLEDGE GRAPH ARCHITECTURE FOR AGENT MEMORY](https://arxiv.org/pdf/2501.13956): 没有消融实验, 不过带时间感知的知识图谱是个不错的方向。 2025-01
