# A Review on the Memory of LLM Agent

## Awesome Papers

| Title | Author |  Date | Memory| memory retrieval mechanism |Code |
|------|------|------|------|------|------|
|[Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents](https://arxiv.org/pdf/2502.06975)| Mathis(Max Planck Institute for Software Systems)|2025-02|该论文提出，情景记忆支持一次性学习特定情境，对于LLM代理在动态环境中的持续学习和长期知识保留至关重要。作者提出了一个情景记忆框架，强调了五个关键属性，并为支持这些属性制定了研究路线图|||
|[Zep: A Temporal Knowledge Graph Architecture for Agent Memory](https://arxiv.org/pdf/2501.13956)| Preston(Zep AI) |2025-01|Zep是一种新颖的AI代理记忆层服务，其核心组件Graphiti是一个时间感知的知识图引擎，能够动态整合非结构化的对话数据和结构化的业务数据。Zep在Deep Memory Retrieval（DMR）基准测试中表现优异，超越了之前的MemGPT系统。|| https://github.com/getzep/zep|
|[On the Structural Memory of LLM Agents](https://export.arxiv.org/pdf/2412.15266)| Ruihong Zeng(University of Glasgow)| 2024-10 |本文旨在研究记忆结构和记忆检索方法如何影响LLM基础代理的性能，具体评估了四种记忆结构（块、知识三元组、原子事实和摘要）以及混合记忆（结合这些组件），还评估了三种广泛使用的记忆检索方法（单步检索、重排序和迭代检索）。通过在四个任务和六个数据集上进行的广泛实验，得出了三个关键见解：（1）不同的记忆结构具有不同的优势，可以针对特定任务进行定制；（2）混合记忆结构在嘈杂环境中表现出显著的弹性；（3）迭代检索在各种场景中始终优于其他方法。本研究旨在激发对LLM基础代理记忆系统设计的进一步研究。|||
|[Evaluating Very Long-Term Conversational Memory of LLM Agents](https://aclanthology.org/2024.acl-long.747.pdf)|Adyasha(University of North Carolina) | 2024-08|该研究引入了一个机器-人类流水线，生成高质量的超长期对话，利用LLM代理架构并基于人物设定和时间事件图。研究收集了LoCoMo数据集，并提出了一个综合评估基准，测量模型的长期记忆能力。结果表明，LLM在理解长对话和长距离时间因果动态方面存在挑战|||
| [MemGPT: Towards LLMs as Operating Systems](https://arxiv.org/pdf/2310.08560)| Charles(Berkeley)| 2023-10 |1. 借鉴类似计算机分层内存管理机制进行agent memory 管理，实现能够分析远远超出基座 LLM 上下文窗口的大型文档。<br> 2. 主上下文(main context):类似操作系统中的主内存,是LLM处理器可以直接访问的固定长度的context窗口。<br> 3. 外部上下文(external context):类似操作系统中的磁盘存储,用于存储超出LLM context窗口的额外信息。信息存储在外部上下文中时对LLM不可见,需要通过特定的函数调用将数据移动到主上下文中。<br> 4. MemGPT主要设计了以下几个函数调用,用于在主上下文和外部上下文之间移动数据: <br> (1) append函数:将指定信息追加到主上下文的working context部分。主要用于会话过程中存储用户信息、特征等。<br> (2) replace函数:替换主上下文working context中的指定文本。主要用于更新主上下文中错误的用户信息。<br> (3) search_recall_storage函数:在回调用存储中搜索指定文本或时间范围内的历史会话。主要用于深度记忆检索任务中查询之前会话内容。<br> (4)search_archival_storage函数:在存档存储中全文搜索或基于向量相似性搜索信息。主要用于文档分析任务中查询相关文档。这些函数调用都是由LLM处理器自主生成的,结构遵循预定义的模式。调用后会触发实际的内存读写操作。读写结果及错误信息会反馈给LLM处理器,形成闭环。|   1. search_recall_storage函数:在回调用存储中搜索指定文本或时间范围内的历史会话。主要用于深度记忆检索任务中查询之前会话内容。<br> 2. search_archival_storage函数:在存档存储中全文搜索或基于向量相似性搜索信息。主要用于文档分析任务中查询相关文档。|[MemGPT](https://github.com/cpacker/MemGPT)|
| [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442)|Joon(Stanford University)| 2023-04 |1. 情景记忆 observation：如实记录Agent和环境和其他Agent的互动历史， 包括事件的描述（semantic descriptions），还包括时间戳（timestamps）和重要性评分（importance scores）。；<br> 2. 语义记忆：对情景记忆的提炼，当情景记忆的重要性总和超过阈值时，触发reflection，提取语义层概念。例如，情景记忆中A在写论文，A在做实验，通过reflection提炼语义：A对科研有很大热情。| 记忆检索：一个多阶段、动态调整的系统，旨在让代理能够在适当的时候“回忆”出相关的经历与信息，从而生成更符合人类心理和行为逻辑的互动反应.<br> 1. Retrieval Trigger: 系统根据代理当前的情境或对话内容自动决定是否触发记忆检索。<br> 2. 多阶段检索过程: 1) **Initial Screening**: 系统会利用诸如时间衰减（recency effect）与重要性评分对所有存储记忆进行初步筛选，选出一批与当前上下文相关的候选记忆. <br> 2)**Contextual Matching and Re-Ranking**: 候选记忆经过大语言模型的语义匹配和重排序（re-ranking）处理，该阶段通过比较当前对话（current context）与候选记忆的语义相关性，确定最符合当前情境的记忆，从而提高检索的准确性。<br> 3) **Memory Summarization**: 最后，将筛选出的记忆片段整合并生成一个简洁的摘要，以便为接下来的反应提供紧凑、相关的背景信息。<br> 3. 整体上，这一机制可以看作是一个多阶段检索管线（multi-stage retrieval pipeline），利用检索增强生成（retrieval-augmented generation）的思想，确保代理在生成反应时能灵活调用与当前情境高度相关的记忆信息。 | [Generative Agents](https://github.com/joonspk-research/generative_agents)|

