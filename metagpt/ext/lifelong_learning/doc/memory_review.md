# A Review on the Memory of LLM Agent

## Awesome Papers

|   ID | Title                                                                                                                       | Author                                                      | Date       | Memory Model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Domain               | Code                                                                       |
|------|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------|----------------------------------------------------------------------------|
|    1 | [A-MEM: Agentic Memory for LLM Agents](https://arxiv.org/pdf/2502.12110)                                                    | Wujiang Xu(Rutgers University)                              | 2025-02-01 | 1. 基于 Zettelkasten 方法的动态知识网络构建 + 自动链接生成 + 记忆演化(复杂多跳推理能力的保证) + 上下文感知检索。<br> 2. A-MEM 在多个基础模型上均优于现有的最先进方法，特别是在需要复杂推理的多跳问答任务中表现尤为突出。<br>                                                                                                                                                                                                                                                                                                                                                                                              | General              | https://github.com/WujiangXu/AgenticMemory                                 |
|    2 | [Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents](https://arxiv.org/pdf/2502.13843)      | Jiahao Liu(Fudan)                                           | 2025-02-01 | 引入分组概念，将User Agent的记忆进行分组处理。  1. 按照商品类型分组：用户对每个类型商品的记忆分别单独存储（领域分离记忆）和跨领域记忆时，仅保留与目标领域相关的内容（领域融合记忆）<br> 2. 按照兴趣偏好对User Agent进行分组: User Agent根据兴趣被分配到不同的兴趣小组，共享记忆存储了小组内用户的近期交互历史。这样可以确保用户行为只影响具有相似兴趣的用户，防止流行度效应扩散到无关用户。<br>                                                                                                                                                                                                                           | RS                   | [AgentCF-plus](https://anonymous.4open.science/r/AgentCF-plus/README.md)   |
|    3 | [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://aclanthology.org/2024.acl-long.747.pdf)             | Adyasha Maharana(University of North Carolina, Chapel Hill) | 2024-08-01 | 1. 问答任务：LLMs在单跳和多跳问题上表现较好，但在时间推理和对抗性问题上表现较差。<br> 2. 事件总结任务：LLMs在总结对话中的事件时存在困难，尤其是在捕捉事件之间的因果和时间关系方面。<br> 3. 多模态对话生成任务：在多模态对话生成任务中，结合对话历史和相关观察（observations）的模型表现优于仅依赖对话历史的模型。这表明利用检索到的相关信息可以显著提高模型生成对话的质量。<br>                                                                                                                                                                                                                                           | General              | https://snap-research.github.io/locomo/, https://github.com/letta-ai/letta |
|    4 | [SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering](https://arxiv.org/pdf/2405.15793)              | John Yang                                                   | 2024-05-01 | 侧重于连接LLM和计算机系统响应的反馈闭环, 从而实现智能体与计算机系统的交互, 没有理论提出。<br>  1. 采用Context management管理记忆, 是React模式的docstring版本, 专注于智能体与计算机交互的上下文; <br> 2. 包含 System Prompt, Demonstration, Issue Statement, 以及agent解决问题时每一步骤的信息(thought & action & env response); 3. 消除冗余信息, 维持可接受的上下文长度措施: <br>    1) 只保留最近5次解决步骤的信息, 其余步骤压缩成一行; <br>    2) 对于生成内容格式错误的问题, 一旦成功解决，就只保留第一次报错信息, 其他报错信息将被删除;<br>    3) 折叠旧的环境响应为占位符消息, 例如, Old output omitted (101 lines); | Software Engineering | https://swe-agent.com/latest/                                              |
|    5 | [MemGPT: Towards LLMs as Operating Systems](https://arxiv.org/pdf/2310.08560)                                               | Charles(Berkeley)                                           | 2023-10-01 | 借鉴类似计算机分层内存管理机制, 实现能够分析远远超出基座 LLM 上下文窗口的大型文档: 分层存储架构（主上下文与外部上下文） + 函数调用驱动的动态上下文管理 + 事件驱动的控制流 + 基于优先级的上下文更新 + 多步检索与函数链式调用 + 长期记忆与动态更新。                                                                                                                                                                                                                                                                                                                                                                        | General              | https://github.com/letta-ai/letta, https://research.memgpt.ai/             |
|    6 | [AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems](https://arxiv.org/pdf/2310.09233) | Junjie Zhang(Renmin University, Tencent)                    | 2023-10-01 | 基于Agent的协同过滤方法，使用User Agent和Item Agent用于模拟 user-item 交互，来解决LLM对RS中用户行为(例如，商品点击)的理解不足的问题。<br>  1. User Agent: 短期记忆记录当前偏好的文本描述，长期记忆记录历史偏好以及偏好演变过程.<br> 2. Item Agent: 记录物品的特征以及潜在用户的偏好.<br> 3. 记忆的更新与传播: 当代理的决策与真实用户行为不一致时，会触发协同反思机制来更新记忆，同时将修正后的偏好信息传播给其他代理，实现协同过滤效果。                                                                                                                                                                                  | RS                   | [AgentCF](https://github.com/leoleojie/AgentCF-WWW)                        |
|    7 | [Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations](https://arxiv.org/pdf/2308.16505) | Xu Huang(Microsoft)                                         | 2023-08-01 | 论文以 LLMs 作为大脑，以推荐模型作为工具，来应对LLM在**对话推荐系统**中的领域知识缺失问题。<br> 1. 将query、工具（召回、排序）以及用户的反馈信息和LLM进行交互，而不是传入候选 items的名称。而将候选 item 放入（工具的）共享候选缓冲区。<br> 2. 结合长期与短期记忆，以保持对用户偏好的全面理解。<br>                                                                                                                                                                                                                                                                                                                       | RS                   | https://github.com/microsoft/RecAI                                         |
|    8 | [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442)                              | Joon(Stanford University)                                   | 2023-04-01 | 带时间戳的事件记忆流 + 多因子相关性检索（近期性/重要性/相似性）+ 定期反思生成抽象洞察 + 动态计划与环境响应 + 记忆驱动的个性化对话生成；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Game                 | https://github.com/joonspk-research/generative_agents                      |

## Others


1. [The Era of Experience](https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf): agent结构的转变，传统的“状态-动作-奖励” -> “经验流 + 自我目标感知 + 长期策略演化”; 2025-04-10

2. [The Second Half](https://ysymyth.github.io/The-Second-Half): 先验知识(prior)比环境(environment)以及经验更重要。 2025-04-10

3. [Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents](https://arxiv.org/pdf/2502.06975): 无实验论证； 2025-02

4. [ZEP: A TEMPORAL KNOWLEDGE GRAPH ARCHITECTURE FOR AGENT MEMORY](https://arxiv.org/pdf/2501.13956): 没有消融实验, 不过带时间感知的知识图谱是个不错的方向。 2025-01

5. [Lifelong Learning of Large Language Model based Agents: A Roadmap](https://arxiv.org/pdf/2501.07278): 只有Agent的 perception, memory, action 三个维度，居然没有Planning？ 2025-01

6. ["My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents](https://arxiv.org/pdf/2404.00573): 通过`上下文相关性` + `时间间隔` + `回忆次数`的函数来量化记忆的巩固程度。 2024-03